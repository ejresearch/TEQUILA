 TEQUILA Platform - Simple Explanation

  What It Is

  TEQUILA is an AI-powered curriculum builder specifically designed for creating Latin lessons. Think of it as a smart assistant that writes an entire year's worth of Latin lessons (36 weeks) automatically
  using AI.

  The Big Picture

  Instead of a teacher spending months writing lesson plans, vocabulary lists, quizzes, and activities, they:
  1. Provide a basic outline (topic, virtue, grammar concepts)
  2. Press a button
  3. Get complete, structured lesson plans generated by AI (ChatGPT or Claude)

  ---
  What's Available in the Code Library

  The codebase is organized into clear sections:

  1. Core Models (src/models/)

  These define what a curriculum looks like:
  - schemas_week.py - Structure for a week (vocabulary, grammar, objectives, chants, assessments)
  - schemas_day.py - Structure for daily lessons (20-25 minute sessions)
  - schemas_role.py - "Sparky" personality (the AI tutor character)
  - schemas_flint.py - Bundle format for packaging lessons

  2. AI Generation System (src/services/)

  The brain that talks to OpenAI/Anthropic:
  - llm_client.py - Talks to ChatGPT or Claude
    - Supports both OpenAI and Anthropic
    - Automatic retry if API fails (3 attempts)
    - Tracks tokens and costs
    - Budget cap protection
    - Dry-run mode (test without spending money)
  - generator_week.py - Creates weekly content:
    - Week specifications
    - Role context (Sparky's personality)
    - Assets (chant charts, glossaries, quizzes)
  - generator_day.py - Creates daily lessons:
    - 7 fields per day (title, summary, grade level, role context, guidelines, full lesson, greeting)
    - Enforces spiral learning (must recall prior content)
  - usage_tracker.py - Monitors spending:
    - Counts tokens used
    - Estimates costs in real dollars
    - Warns when approaching budget limit
  - validator.py - Quality control:
    - Checks if generated content follows rules
    - Validates against Pydantic schemas
    - Reports errors/warnings
  - storage.py - File management:
    - Saves each piece of content as separate files
    - Atomic structure (prevents conflicts)
    - Compiles individual parts into complete documents
  - exporter.py - Creates ZIP packages of completed weeks

  3. Command-Line Tools (src/cli/)

  Scripts to run generation tasks:
  - hydrate_week_from_llm.py - Generate one complete week
  - hydrate_day_from_llm.py - Generate one day
  - hydrate_all_from_llm.py - Generate all 36 weeks ($$$ expensive!)
  - build_week.py - Scaffold empty week structure
  - validate_week_and_kit.py - Check quality

  4. Web API (src/app.py)

  A REST API server (FastAPI) with endpoints:

  Public (no password needed):
  - GET /api/v1/usage - Check how much money you've spent
  - GET /api/v1/weeks/{week}/spec/compiled - Read a week's plan
  - POST /api/v1/weeks/{week}/validate - Check if week is valid

  Protected (requires API key):
  - POST /api/v1/gen/weeks/{week}/spec - Generate week plan (costs money)
  - POST /api/v1/gen/weeks/{week}/hydrate - Generate entire week (more money)
  - POST /api/v1/gen/weeks/{week}/days/{day}/document - Generate single day

  5. Configuration (src/config.py)

  Settings you control in .env file:
  - Which AI to use (OpenAI or Anthropic)
  - API keys
  - Model name (gpt-4o, claude-3-5-sonnet, etc.)
  - Temperature (creativity level)
  - Budget caps
  - Dry-run mode (test without spending)

  ---
  Key Features Built-In

  Safety Features:

  - Budget Protection - Won't generate if you hit spending limit
  - API Authentication - Password-protect expensive operations
  - Dry-Run Mode - Test everything without API calls
  - Cost Tracking - See exactly how much each generation costs

  Quality Features:

  - Strict Validation - AI output must match exact structure (Pydantic schemas)
  - Spiral Learning Enforcement - Code forces vocabulary/grammar recycling
  - Provenance Tracking - Every file records which AI made it, when, and cost
  - Failure Logging - Saves bad AI responses as *_INVALID.json for debugging

  Pedagogical Intelligence:

  - Vocabulary items marked as "recycled" from prior weeks
  - Grammar must reference earlier concepts
  - Assessments must test 25%+ prior content
  - Misconception tracking for common student errors
  - Virtue integration (classical education approach)

  ---
  How Files Are Stored

  Each week gets a folder like this:
  curriculum/LatinA/Week01/
  ├── Week_Spec/              # 12 separate JSON files
  │   ├── 01_metadata.json    # Week info
  │   ├── 02_objectives.json  # Learning goals
  │   ├── 03_vocabulary.json  # Word list
  │   ├── 04_grammar_focus.md # Grammar concepts
  │   └── 99_compiled_week_spec.json  # Everything combined
  ├── Role_Context/           # Sparky personality (7 files)
  ├── activities/
  │   ├── Day1/              # 6 field files
  │   ├── Day2/
  │   ├── Day3/
  │   └── Day4/
  └── assets/                # Supplementary materials
      ├── ChantChart.txt
      ├── Glossary.txt
      └── QuizPacket.txt

  Why split into small files?
  - Git-friendly (fewer merge conflicts)
  - Edit one part without regenerating everything
  - Track changes at granular level

  ---
  Migrating Existing Days to 7-Field Architecture

  If you have existing 6-field days, use the migration script:

  # Migrate a single week
  python -m src.cli.migrate_to_7field --week 1

  # Migrate all weeks
  python -m src.cli.migrate_to_7field --all

  # Preview changes without modifying files
  python -m src.cli.migrate_to_7field --dry-run --all

  The migration script:
  1. Detects legacy 6-field days
  2. Creates default role_context (04_role_context.json) from week-level Role_Context
  3. Renames fields: 04→05, 05→06, 06→07
  4. Validates migrated structure
  5. Adds migration provenance metadata

  ---
  What You Can Do With This

  As a developer:
  - Generate curriculum for any subject (not just Latin) by tweaking schemas
  - Switch AI providers without changing code
  - Monitor and control costs programmatically
  - Build custom workflows with the API

  As an educator:
  - Generate 36 weeks of Latin lessons in hours instead of months
  - Test different AI models to find best quality/cost ratio
  - Customize generated content by editing individual files
  - Export validated weeks as ZIP files for distribution

  As a school administrator:
  - Set budget caps to prevent overspending
  - Require API authentication to protect endpoints
  - Track usage across multiple users
  - Review all content before classroom deployment

  ---
  Summary

  TEQUILA = AI curriculum factory for Latin instruction

  What's in the code:
  1. AI clients that talk to OpenAI/Anthropic with safety controls
  2. Generators that produce structured lesson content
  3. Validators that enforce pedagogical rules
  4. APIs to trigger generation and read results
  5. CLI tools for batch operations
  6. Cost tracking to monitor spending
  7. File system that stores content in atomic pieces

  It's production-ready with multiple layers of protection: authentication, budget caps, validation, provenance tracking, and human review checkpoints.

