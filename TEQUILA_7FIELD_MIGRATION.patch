################################################################################
# TEQUILA SEVEN-FIELD DAY ARCHITECTURE MIGRATION PATCH
#
# OVERVIEW:
# This patch migrates TEQUILA from 6-field to 7-field day structure by inserting
# a new "04_role_context.json" field between grade_level and guidelines, then
# reindexing the remaining fields.
#
# FIELD MAPPING (old → new):
#   01_class_name.txt           → 01_class_name.txt (unchanged)
#   02_summary.md               → 02_summary.md (unchanged)
#   03_grade_level.txt          → 03_grade_level.txt (unchanged)
#   [NEW]                       → 04_role_context.json (NEW)
#   04_guidelines_for_sparky.md → 05_guidelines_for_sparky.md (reindexed)
#   05_document_for_sparky.json → 06_document_for_sparky.json (reindexed)
#   06_sparkys_greeting.txt     → 07_sparkys_greeting.txt (reindexed)
#
# CHANGES APPLIED:
# 1. schemas_flint.py - Add role_context field to FlintBundle
# 2. storage.py - Update DAY_FIELDS constant and add role_context I/O functions
# 3. generator_day.py - Update generation logic and scaffold for 7 fields
# 4. validator.py - Update validation to check 7 fields and role_context presence
# 5. prompts/kit_tasks.py - Add task_day_role_context prompt function
# 6. prompts/day_role_context_system.txt - New prompt template for role_context
# 7. migrate_to_7field.py - Migration script for existing 6-field days
# 8. tests/test_7field_migration.py - New test suite for migration
# 9. README.md - Update documentation to reflect 7-field structure
#
# ASSUMPTIONS:
# - Legacy 6-field days exist in curriculum/LatinA/Week*/activities/Day*
# - role_context defaults derived from week-level Role_Context when migrating
# - All existing validation, provenance, cost tracking remains unchanged
# - Backward compatibility: read functions detect 6-field vs 7-field layouts
#
# COMMIT SEQUENCE:
# 1. Update schemas (schemas_flint.py)
# 2. Update storage layer (storage.py)
# 3. Update generation logic (generator_day.py, prompts/*)
# 4. Update validation (validator.py)
# 5. Add migration script (migrate_to_7field.py)
# 6. Add tests (tests/test_7field_migration.py)
# 7. Update documentation (README.md)
#
################################################################################

diff --git a/src/models/schemas_flint.py b/src/models/schemas_flint.py
index a1b2c3d..e4f5g6h 100644
--- a/src/models/schemas_flint.py
+++ b/src/models/schemas_flint.py
@@ -5,12 +5,14 @@ from typing import Optional, Dict, Any

 class FlintBundle(BaseModel):
     """
-    The six Flint fields that make up a day's metadata.
+    The seven Flint fields that make up a day's metadata.

     These fields provide context for the lesson builder system (Flint)
     and are separate from the detailed lesson plan (document_for_sparky).
+
+    Field 04 (role_context) added in TEQUILA 7-field architecture (Patch TEQUILA Phase 2).
     """
     class_name: str = Field(
         ...,
         min_length=1,
@@ -30,6 +32,19 @@ class FlintBundle(BaseModel):
         description="Target grade range (e.g., '3-5', '6-8')"
     )

+    role_context: Optional[Dict[str, Any]] = Field(
+        None,
+        description=(
+            "Day-specific role context for Sparky (teaching persona, behavioral hints). "
+            "Includes: sparky_role (str), focus_mode (str), hints_enabled (bool), "
+            "spiral_emphasis (list), encouragement_triggers (list). "
+            "If omitted, system will inherit from week-level Role_Context."
+        )
+    )
+
     guidelines_for_sparky: str = Field(
         ...,
         min_length=100,
@@ -51,6 +66,11 @@ class FlintBundle(BaseModel):
     class Config:
         json_schema_extra = {
             "example": {
                 "class_name": "Week 11 Day 1: First Declension Nouns",
                 "summary": "Students will learn the nominative and accusative cases of first declension nouns. Focus on proper noun endings and their use in simple sentences.",
                 "grade_level": "3-5",
+                "role_context": {
+                    "sparky_role": "patient guide",
+                    "focus_mode": "introduction",
+                    "hints_enabled": True,
+                    "spiral_emphasis": ["Week 10 vocabulary", "prior noun forms"],
+                    "encouragement_triggers": ["first attempt", "corrected error"]
+                },
                 "guidelines_for_sparky": "# Teaching Notes\n\n- Use visual aids for noun endings\n- Practice with familiar vocabulary first\n- Emphasize sing-song chanting for memorization",
                 "sparkys_greeting": "Welcome, young Latin scholars! Today we begin our journey into the beautiful world of Latin nouns."
             }
         }

diff --git a/src/services/storage.py b/src/services/storage.py
index 1a2b3c4..5d6e7f8 100644
--- a/src/services/storage.py
+++ b/src/services/storage.py
@@ -1,20 +1,35 @@
 """Storage service for curriculum file operations."""
 import json
 from pathlib import Path
-from typing import Dict, Any, Optional
+from typing import Dict, Any, Optional, List


-# Field names for Day activities (Flint fields)
+# Field names for Day activities (Flint fields) - 7-field architecture
 DAY_FIELDS = [
     "01_class_name.txt",
     "02_summary.md",
     "03_grade_level.txt",
+    "04_role_context.json",
+    "05_guidelines_for_sparky.md",
+    "06_document_for_sparky.json",
+    "07_sparkys_greeting.txt"
+]
+
+# Legacy 6-field layout (for backward compatibility)
+LEGACY_DAY_FIELDS = [
+    "01_class_name.txt",
+    "02_summary.md",
+    "03_grade_level.txt",
     "04_guidelines_for_sparky.md",
     "05_document_for_sparky.json",
     "06_sparkys_greeting.txt"
 ]

+# Mapping: old field name → new field name
+FIELD_MIGRATION_MAP = {
+    "04_guidelines_for_sparky.md": "05_guidelines_for_sparky.md",
+    "05_document_for_sparky.json": "06_document_for_sparky.json",
+    "06_sparkys_greeting.txt": "07_sparkys_greeting.txt"
+}
+
 # Week spec parts
 WEEK_SPEC_PARTS = [
@@ -108,6 +123,57 @@ def write_json(path: Path, data: Dict[str, Any]) -> None:
         json.dump(data, f, indent=2, ensure_ascii=False)
         f.write("\n")


+def detect_day_layout(week_number: int, day_number: int) -> str:
+    """
+    Detect whether a day uses 6-field (legacy) or 7-field layout.
+
+    Returns:
+        "7field" if 04_role_context.json exists, else "6field"
+    """
+    role_context_path = day_field_path(week_number, day_number, "04_role_context.json")
+    if role_context_path.exists():
+        return "7field"
+
+    # Check for legacy 04_guidelines_for_sparky.md
+    legacy_guidelines = day_field_path(week_number, day_number, "04_guidelines_for_sparky.md")
+    if legacy_guidelines.exists():
+        return "6field"
+
+    # Default to 7-field for new scaffolding
+    return "7field"
+
+
+def get_day_fields(week_number: int, day_number: int) -> List[str]:
+    """
+    Get the appropriate field list (6 or 7 fields) based on detected layout.
+
+    Returns:
+        List of field filenames for this day's layout.
+    """
+    layout = detect_day_layout(week_number, day_number)
+    return DAY_FIELDS if layout == "7field" else LEGACY_DAY_FIELDS
+
+
+def read_role_context(week_number: int, day_number: int) -> Optional[Dict[str, Any]]:
+    """
+    Read day-specific role_context if present, else derive from week-level Role_Context.
+
+    Returns:
+        role_context dict or None if not found.
+    """
+    role_context_path = day_field_path(week_number, day_number, "04_role_context.json")
+    if role_context_path.exists():
+        return read_json(role_context_path)
+
+    # Fallback: derive from week-level Role_Context
+    week_rc_path = role_context_part_path(week_number, "identity.json")
+    if week_rc_path.exists():
+        identity = read_json(week_rc_path)
+        return {
+            "sparky_role": identity.get("character_name", "Sparky"),
+            "focus_mode": "general",
+            "hints_enabled": True,
+            "spiral_emphasis": [],
+            "encouragement_triggers": ["first_attempt", "corrected_error"]
+        }
+    return None
+
+
 def compile_day_flint_bundle(week_number: int, day_number: int) -> Dict[str, Any]:
     """
-    Compile all six Flint field files into a single JSON bundle.
+    Compile all Flint field files (6 or 7 depending on layout) into a single JSON bundle.

     Returns a dictionary with field names as keys and their content as values.
+
+    Backward compatible: automatically detects and reads 6-field or 7-field layouts.
     """
     bundle = {}
+    fields = get_day_fields(week_number, day_number)

-    for field in DAY_FIELDS:
+    for field in fields:
         field_path = day_field_path(week_number, day_number, field)
         if not field_path.exists():
             bundle[field] = None
             continue

diff --git a/src/services/generator_day.py b/src/services/generator_day.py
index 7a8b9c0..1d2e3f4 100644
--- a/src/services/generator_day.py
+++ b/src/services/generator_day.py
@@ -11,7 +11,8 @@ from .storage import (
     write_json
 )
 from .llm_client import LLMClient
-from .prompts.kit_tasks import task_day_fields, task_day_document
+from .prompts.kit_tasks import (
+    task_day_fields, task_day_document, task_day_role_context
+)


 def get_field_template_path(field_name: str) -> Path:
@@ -22,13 +23,13 @@ def get_field_template_path(field_name: str) -> Path:
 def scaffold_day(week_number: int, day_number: int) -> Path:
     """
     Create the complete directory structure and files for a specific day.

-    Creates the six Flint field files:
+    Creates the seven Flint field files:
     - 01_class_name.txt
     - 02_summary.md
     - 03_grade_level.txt
-    - 04_guidelines_for_sparky.md
-    - 05_document_for_sparky.json
-    - 06_sparkys_greeting.txt
+    - 04_role_context.json (NEW in 7-field architecture)
+    - 05_guidelines_for_sparky.md (reindexed from 04)
+    - 06_document_for_sparky.json (reindexed from 05)
+    - 07_sparkys_greeting.txt (reindexed from 06)

     Args:
         week_number: The week number (1-36)
@@ -99,7 +100,7 @@ def scaffold_week_days(week_number: int) -> list[Path]:

 def generate_day_fields(week: int, day: int, client: LLMClient) -> List[Path]:
     """
-    Generate the six Flint field files for a day using LLM.
+    Generate the seven Flint field files for a day using LLM.

     Args:
         week: Week number (1-36)
@@ -141,11 +142,31 @@ def generate_day_fields(week: int, day: int, client: LLMClient) -> List[Path]:
                 "sparkys_greeting": "Welcome to Latin!"
             }

+    # Generate role_context separately
+    sys_rc, usr_rc, _ = task_day_role_context(week_spec, day)
+    response_rc = client.generate(prompt=usr_rc, system=sys_rc)
+
+    if response_rc.json:
+        role_context_data = response_rc.json
+    else:
+        try:
+            role_context_data = orjson.loads(response_rc.text)
+        except Exception:
+            # Fallback minimal role_context
+            role_context_data = {
+                "sparky_role": "encouraging guide",
+                "focus_mode": f"day_{day}_focus",
+                "hints_enabled": True,
+                "spiral_emphasis": [],
+                "encouragement_triggers": ["first_attempt"]
+            }
+
-    # Write field files (excluding document_for_sparky which is separate)
+    # Write field files (excluding document_for_sparky which is generated separately)
     field_mapping = {
         "01_class_name.txt": fields_data.get("class_name", ""),
         "02_summary.md": fields_data.get("summary", ""),
         "03_grade_level.txt": fields_data.get("grade_level", ""),
-        "04_guidelines_for_sparky.md": fields_data.get("guidelines_for_sparky", ""),
-        "06_sparkys_greeting.txt": fields_data.get("sparkys_greeting", "")
+        "05_guidelines_for_sparky.md": fields_data.get("guidelines_for_sparky", ""),
+        "07_sparkys_greeting.txt": fields_data.get("sparkys_greeting", "")
     }

     created_paths = []
     for field_name, content in field_mapping.items():
         field_path = day_field_path(week, day, field_name)
         write_file(field_path, str(content))
         created_paths.append(field_path)
+
+    # Write role_context JSON
+    rc_path = day_field_path(week, day, "04_role_context.json")
+    write_json(rc_path, role_context_data)
+    created_paths.append(rc_path)

     return created_paths

@@ -200,7 +221,7 @@ def generate_day_document(week: int, day: int, client: LLMClient) -> Path:
             raise ValueError(f"LLM returned invalid JSON: {e}")

-    # Write document_for_sparky.json
-    doc_path = day_field_path(week, day, "05_document_for_sparky.json")
+    # Write document_for_sparky.json (now field 06)
+    doc_path = day_field_path(week, day, "06_document_for_sparky.json")
     write_json(doc_path, doc_data)

     return doc_path

diff --git a/src/services/validator.py b/src/services/validator.py
index 9a0b1c2..3d4e5f6 100644
--- a/src/services/validator.py
+++ b/src/services/validator.py
@@ -10,7 +10,8 @@ from .storage import (
     compile_day_flint_bundle,
     compile_week_spec,
     compile_role_context,
-    DAY_FIELDS,
+    get_day_fields,
+    detect_day_layout,
     WEEK_SPEC_PARTS,
     ROLE_CONTEXT_PARTS
 )
@@ -64,10 +65,11 @@ class ValidationResult:

 def validate_day_fields(week_number: int, day_number: int) -> ValidationResult:
     """
-    Validate that all required Flint field files exist for a day.
+    Validate that all required Flint field files exist for a day (6 or 7 fields).

     Checks:
-    - All six field files exist
+    - All field files exist (auto-detects 6-field vs 7-field layout)
+    - 7-field layout required for new days; 6-field is legacy
     - JSON files are valid JSON
     - Files are not empty (except where appropriate)
     """
@@ -80,7 +82,14 @@ def validate_day_fields(week_number: int, day_number: int) -> ValidationResult:
         )
         return result

-    for field in DAY_FIELDS:
+    layout = detect_day_layout(week_number, day_number)
+    fields = get_day_fields(week_number, day_number)
+
+    if layout == "6field":
+        result.add_warning(
+            f"Week{week_number:02d}/Day{day_number}",
+            "Day uses legacy 6-field layout. Consider migrating to 7-field with role_context."
+        )
+
+    for field in fields:
         field_path = day_path / field
         location = f"Week{week_number:02d}/Day{day_number}/{field}"

@@ -100,6 +109,21 @@ def validate_day_fields(week_number: int, day_number: int) -> ValidationResult:
         if field_path.stat().st_size == 0:
             result.add_warning(location, "Field file is empty")
+
+    # Validate role_context structure if present
+    if layout == "7field":
+        rc_path = day_path / "04_role_context.json"
+        if rc_path.exists():
+            try:
+                rc_data = json.loads(rc_path.read_text(encoding="utf-8"))
+                required_keys = ["sparky_role", "focus_mode", "hints_enabled"]
+                for key in required_keys:
+                    if key not in rc_data:
+                        result.add_warning(
+                            f"Week{week_number:02d}/Day{day_number}/04_role_context.json",
+                            f"role_context missing recommended key: {key}"
+                        )
+            except Exception as e:
+                result.add_error(
+                    f"Week{week_number:02d}/Day{day_number}/04_role_context.json",
+                    f"role_context validation failed: {e}"
+                )

     return result

@@ -120,7 +144,10 @@ def validate_day_4_spiral_content(week_number: int) -> ValidationResult:
         return result

     day4_path = day_dir(week_number, 4)
-    guidelines_path = day4_path / "04_guidelines_for_sparky.md"
+
+    # Handle both legacy and new field naming
+    layout = detect_day_layout(week_number, 4)
+    guidelines_file = "05_guidelines_for_sparky.md" if layout == "7field" else "04_guidelines_for_sparky.md"
+    guidelines_path = day4_path / guidelines_file

     if guidelines_path.exists():
         content = guidelines_path.read_text(encoding="utf-8").lower()

diff --git a/src/services/prompts/kit_tasks.py b/src/services/prompts/kit_tasks.py
index a1b2c3d..e4f5g6h 100644
--- a/src/services/prompts/kit_tasks.py
+++ b/src/services/prompts/kit_tasks.py
@@ -128,10 +128,54 @@ def task_assets(week_spec: dict) -> Tuple[str, str, Optional[Dict]]:
     return sys, usr, None


+def task_day_role_context(week_spec: dict, day: int) -> Tuple[str, str, Optional[Dict]]:
+    """
+    Generate prompts for day-specific role_context (the 4th Flint field).
+
+    This field defines Sparky's behavioral parameters for the specific day,
+    including teaching persona, hint availability, spiral emphasis, etc.
+
+    Args:
+        week_spec: The week specification data
+        day: Day number (1-4)
+
+    Returns:
+        (system_prompt, user_prompt, json_schema_hint)
+    """
+    sys = _load_system_prompt("day_role_context_system.txt")
+
+    usr = (
+        f"Generate day-specific role_context JSON for Week {week_spec.get('metadata', {}).get('week_number', '?')} Day {day}.\n\n"
+        "Week metadata and spiral links:\n"
+        + orjson.dumps(
+            {
+                "metadata": week_spec.get("metadata", {}),
+                "spiral_links": week_spec.get("spiral_links", {}),
+                "day": day,
+                "day_focus": _get_day_focus(day)
+            },
+            option=orjson.OPT_INDENT_2
+        ).decode()
+    )
+
+    schema = {
+        "type": "object",
+        "properties": {
+            "sparky_role": {"type": "string"},
+            "focus_mode": {"type": "string"},
+            "hints_enabled": {"type": "boolean"},
+            "spiral_emphasis": {"type": "array", "items": {"type": "string"}},
+            "encouragement_triggers": {"type": "array", "items": {"type": "string"}}
+        },
+        "required": ["sparky_role", "focus_mode", "hints_enabled"]
+    }
+
+    return sys, usr, schema
+
+
+def _get_day_focus(day: int) -> str:
+    """Get pedagogical focus label for day number."""
+    focuses = {
+        1: "introduction_and_exploration",
+        2: "practice_and_reinforcement",
+        3: "application_and_extension",
+        4: "review_and_spiral_25pct"
+    }
+    return focuses.get(day, "general")
+
+
 def task_day_fields(week_spec: dict, day: int) -> Tuple[str, str, Optional[Dict]]:
     """
-    Generate prompts for day Flint fields (the six text snippets).
+    Generate prompts for day Flint fields (class_name, summary, grade_level, guidelines, greeting).
+
+    Note: role_context (field 04) is generated separately via task_day_role_context.

     Args:
         week_spec: The week specification data
@@ -141,11 +185,11 @@ def task_day_fields(week_spec: dict, day: int) -> Tuple[str, str, Optional[Dict
         (system_prompt, user_prompt, json_schema_hint)
     """
     sys = (
-        "Produce the six Flint field texts for a single day:\n"
+        "Produce the text Flint fields for a single day (excluding role_context):\n"
         "1. class_name - short lesson title\n"
         "2. summary - 2-3 sentence overview\n"
         "3. grade_level - target grade range\n"
-        "4. guidelines_for_sparky - teaching notes (markdown)\n"
-        "5. sparkys_greeting - 1-2 sentence student greeting\n\n"
+        "4. guidelines_for_sparky - teaching notes (markdown, now field 05)\n"
+        "5. sparkys_greeting - 1-2 sentence student greeting (now field 07)\n\n"
         "Return as JSON object with these keys.\n"
         "Keep greeting warm and encouraging (≤2 sentences)."
     )

diff --git a/src/services/prompts/day_role_context_system.txt b/src/services/prompts/day_role_context_system.txt
new file mode 100644
index 0000000..a1b2c3d
--- /dev/null
+++ b/src/services/prompts/day_role_context_system.txt
@@ -0,0 +1,32 @@
+You are generating a day-specific role_context JSON for Sparky, the AI Latin tutor.
+
+This role_context field (new in 7-field architecture) defines Sparky's behavioral parameters
+for a single day lesson. It sits between grade_level (field 03) and guidelines (field 05).
+
+Required fields in your JSON output:
+- sparky_role (string): Sparky's teaching persona for this day (e.g., "patient guide", "socratic questioner", "cheerleader")
+- focus_mode (string): Pedagogical mode (e.g., "introduction", "practice", "review", "assessment")
+- hints_enabled (boolean): Whether Sparky can give progressive hints (true/false)
+- spiral_emphasis (array of strings): Prior content areas to emphasize (e.g., ["Week 10 vocabulary", "noun declensions"])
+- encouragement_triggers (array of strings): Events that trigger encouragement (e.g., ["first_attempt", "corrected_error", "struggling"])
+
+Optional fields:
+- max_hints (integer): Maximum hints before revealing answer (default: 3)
+- wait_time_seconds (integer): Wait time for student responses (default: 5)
+- virtue_callout (string): How to weave in week's virtue theme
+
+CRITICAL - Day-specific adaptations:
+- Day 1: focus_mode should be "introduction_and_exploration"
+- Day 2: focus_mode should be "practice_and_reinforcement"
+- Day 3: focus_mode should be "application_and_extension"
+- Day 4: focus_mode should be "review_and_spiral", spiral_emphasis MUST include ≥2 prior content areas
+
+CRITICAL - Spiral learning integration:
+- If spiral_links are provided in week_spec, populate spiral_emphasis with specific references
+- Use YAML-style references format when possible: "Week 10: vocabulary items 1-5"
+
+CRITICAL - Output format:
+- Return ONLY valid JSON
+- No markdown, no comments, no backticks
+- Ensure all required fields are present
+- Keep descriptions concise (sparky_role ≤50 chars, focus_mode ≤30 chars)

diff --git a/src/cli/migrate_to_7field.py b/src/cli/migrate_to_7field.py
new file mode 100644
index 0000000..a1b2c3d
--- /dev/null
+++ b/src/cli/migrate_to_7field.py
@@ -0,0 +1,178 @@
+#!/usr/bin/env python3
+"""
+Migration script: Convert 6-field day layouts to 7-field architecture.
+
+This script:
+1. Detects all days with legacy 6-field layout
+2. Creates default role_context (04_role_context.json) from week-level Role_Context
+3. Renames/moves existing fields to new indices:
+   - 04_guidelines_for_sparky.md → 05_guidelines_for_sparky.md
+   - 05_document_for_sparky.json → 06_document_for_sparky.json
+   - 06_sparkys_greeting.txt → 07_sparkys_greeting.txt
+4. Validates migrated structure
+5. Creates migration provenance file
+
+Usage:
+    python -m src.cli.migrate_to_7field --week 1            # Migrate Week 1
+    python -m src.cli.migrate_to_7field --all              # Migrate all weeks
+    python -m src.cli.migrate_to_7field --dry-run --all    # Preview changes
+"""
+import argparse
+import json
+from pathlib import Path
+from datetime import datetime
+from typing import Dict, Any, List
+from ..services.storage import (
+    week_dir,
+    day_dir,
+    day_field_path,
+    role_context_part_path,
+    detect_day_layout,
+    write_json,
+    read_json,
+    FIELD_MIGRATION_MAP
+)
+from ..services.validator import validate_day_fields
+
+
+def derive_default_role_context(week_number: int, day_number: int) -> Dict[str, Any]:
+    """
+    Derive a default role_context from week-level Role_Context.
+
+    Args:
+        week_number: Week number
+        day_number: Day number (1-4)
+
+    Returns:
+        role_context dict with defaults
+    """
+    # Try to read week-level identity
+    identity_path = role_context_part_path(week_number, "identity.json")
+    sparky_role = "encouraging Latin guide"
+
+    if identity_path.exists():
+        try:
+            identity = read_json(identity_path)
+            sparky_role = identity.get("character_name", "Sparky the Latin Guide")
+        except Exception:
+            pass
+
+    # Day-specific focus modes
+    focus_modes = {
+        1: "introduction_and_exploration",
+        2: "practice_and_reinforcement",
+        3: "application_and_extension",
+        4: "review_and_spiral"
+    }
+
+    return {
+        "sparky_role": sparky_role,
+        "focus_mode": focus_modes.get(day_number, "general"),
+        "hints_enabled": True,
+        "spiral_emphasis": [] if day_number < 2 else [f"Week {max(1, week_number - 1)} content"],
+        "encouragement_triggers": ["first_attempt", "corrected_error", "progress_shown"],
+        "__migration": {
+            "migrated_at": datetime.utcnow().isoformat() + "Z",
+            "migration_script": "migrate_to_7field.py",
+            "source": "week_role_context_default"
+        }
+    }
+
+
+def migrate_day(week_number: int, day_number: int, dry_run: bool = False) -> Dict[str, Any]:
+    """
+    Migrate a single day from 6-field to 7-field layout.
+
+    Args:
+        week_number: Week number
+        day_number: Day number (1-4)
+        dry_run: If True, only preview changes without modifying files
+
+    Returns:
+        Migration result dict with status and actions taken
+    """
+    result = {
+        "week": week_number,
+        "day": day_number,
+        "status": "skipped",
+        "actions": [],
+        "errors": []
+    }
+
+    layout = detect_day_layout(week_number, day_number)
+
+    if layout == "7field":
+        result["status"] = "already_7field"
+        result["actions"].append("No migration needed (already 7-field)")
+        return result
+
+    day_path = day_dir(week_number, day_number)
+    if not day_path.exists():
+        result["status"] = "error"
+        result["errors"].append("Day directory does not exist")
+        return result
+
+    # Step 1: Create role_context
+    role_context_path = day_field_path(week_number, day_number, "04_role_context.json")
+    role_context_data = derive_default_role_context(week_number, day_number)
+
+    if not dry_run:
+        write_json(role_context_path, role_context_data)
+    result["actions"].append(f"Created {role_context_path.name}")
+
+    # Step 2: Rename/move fields 04, 05, 06 → 05, 06, 07
+    for old_name, new_name in FIELD_MIGRATION_MAP.items():
+        old_path = day_field_path(week_number, day_number, old_name)
+        new_path = day_field_path(week_number, day_number, new_name)
+
+        if old_path.exists():
+            if not dry_run:
+                old_path.rename(new_path)
+            result["actions"].append(f"Renamed {old_name} → {new_name}")
+        else:
+            result["errors"].append(f"Expected field {old_name} not found")
+
+    # Step 3: Validate migrated structure
+    if not dry_run:
+        validation = validate_day_fields(week_number, day_number)
+        if validation.is_valid():
+            result["status"] = "migrated_success"
+        else:
+            result["status"] = "migrated_with_warnings"
+            result["errors"].extend([str(e) for e in validation.errors])
+    else:
+        result["status"] = "dry_run_success"
+
+    return result
+
+
+def migrate_week(week_number: int, dry_run: bool = False) -> List[Dict[str, Any]]:
+    """Migrate all days in a week."""
+    results = []
+    for day in range(1, 5):
+        result = migrate_day(week_number, day, dry_run)
+        results.append(result)
+    return results
+
+
+def main():
+    parser = argparse.ArgumentParser(description="Migrate TEQUILA days from 6-field to 7-field layout")
+    parser.add_argument("--week", type=int, help="Week number to migrate (1-36)")
+    parser.add_argument("--all", action="store_true", help="Migrate all weeks")
+    parser.add_argument("--dry-run", action="store_true", help="Preview changes without modifying files")
+
+    args = parser.parse_args()
+
+    if args.all:
+        weeks = range(1, 37)
+    elif args.week:
+        weeks = [args.week]
+    else:
+        parser.error("Must specify --week or --all")
+
+    for week in weeks:
+        print(f"\n{'[DRY RUN] ' if args.dry_run else ''}Migrating Week {week}...")
+        results = migrate_week(week, args.dry_run)
+        for res in results:
+            print(f"  Day {res['day']}: {res['status']}")
+            for action in res["actions"]:
+                print(f"    ✓ {action}")
+            for error in res["errors"]:
+                print(f"    ✗ {error}")
+
+
+if __name__ == "__main__":
+    main()

diff --git a/tests/test_7field_migration.py b/tests/test_7field_migration.py
new file mode 100644
index 0000000..a1b2c3d
--- /dev/null
+++ b/tests/test_7field_migration.py
@@ -0,0 +1,143 @@
+"""Test suite for 7-field day architecture migration."""
+import pytest
+from pathlib import Path
+import json
+import tempfile
+import shutil
+from src.services.storage import (
+    day_dir,
+    day_field_path,
+    detect_day_layout,
+    get_day_fields,
+    write_file,
+    write_json,
+    DAY_FIELDS,
+    LEGACY_DAY_FIELDS
+)
+from src.cli.migrate_to_7field import migrate_day, derive_default_role_context
+from src.services.validator import validate_day_fields
+
+
+@pytest.fixture
+def temp_curriculum(tmp_path, monkeypatch):
+    """Create a temporary curriculum directory for testing."""
+    curriculum_base = tmp_path / "curriculum" / "LatinA"
+    curriculum_base.mkdir(parents=True)
+
+    # Monkeypatch the curriculum base path
+    import src.services.storage as storage_module
+    original_base = storage_module.get_curriculum_base
+    monkeypatch.setattr(storage_module, "get_curriculum_base", lambda: curriculum_base)
+
+    yield curriculum_base
+
+    # Cleanup
+    monkeypatch.setattr(storage_module, "get_curriculum_base", original_base)
+
+
+def create_legacy_day(week: int, day: int):
+    """Helper: Create a 6-field legacy day structure."""
+    day_path = day_dir(week, day)
+    day_path.mkdir(parents=True, exist_ok=True)
+
+    for field in LEGACY_DAY_FIELDS:
+        field_path = day_field_path(week, day, field)
+        if field.endswith(".json"):
+            write_json(field_path, {"test": "data"})
+        else:
+            write_file(field_path, "Test content")
+
+
+def create_7field_day(week: int, day: int):
+    """Helper: Create a 7-field day structure."""
+    day_path = day_dir(week, day)
+    day_path.mkdir(parents=True, exist_ok=True)
+
+    for field in DAY_FIELDS:
+        field_path = day_field_path(week, day, field)
+        if field.endswith(".json"):
+            write_json(field_path, {"test": "data"})
+        else:
+            write_file(field_path, "Test content")
+
+
+class TestLayoutDetection:
+    """Test day layout detection (6-field vs 7-field)."""
+
+    def test_detect_7field_layout(self, temp_curriculum):
+        """Should detect 7-field layout when role_context exists."""
+        create_7field_day(1, 1)
+        assert detect_day_layout(1, 1) == "7field"
+
+    def test_detect_6field_layout(self, temp_curriculum):
+        """Should detect 6-field legacy layout."""
+        create_legacy_day(1, 1)
+        assert detect_day_layout(1, 1) == "6field"
+
+    def test_get_day_fields_7field(self, temp_curriculum):
+        """Should return 7 fields for 7-field layout."""
+        create_7field_day(2, 1)
+        fields = get_day_fields(2, 1)
+        assert len(fields) == 7
+        assert "04_role_context.json" in fields
+
+    def test_get_day_fields_6field(self, temp_curriculum):
+        """Should return 6 fields for legacy layout."""
+        create_legacy_day(2, 1)
+        fields = get_day_fields(2, 1)
+        assert len(fields) == 6
+        assert "04_guidelines_for_sparky.md" in fields
+
+
+class TestRoleContextDefaults:
+    """Test default role_context generation."""
+
+    def test_derive_default_role_context_day1(self):
+        """Should use 'introduction' focus for Day 1."""
+        rc = derive_default_role_context(1, 1)
+        assert rc["focus_mode"] == "introduction_and_exploration"
+        assert rc["hints_enabled"] is True
+        assert "__migration" in rc
+
+    def test_derive_default_role_context_day4(self):
+        """Should use 'review_and_spiral' focus for Day 4."""
+        rc = derive_default_role_context(3, 4)
+        assert rc["focus_mode"] == "review_and_spiral"
+        assert len(rc["spiral_emphasis"]) > 0  # Should reference prior week
+
+
+class TestMigration:
+    """Test migration from 6-field to 7-field."""
+
+    def test_migrate_day_creates_role_context(self, temp_curriculum):
+        """Should create role_context file during migration."""
+        create_legacy_day(5, 2)
+        result = migrate_day(5, 2, dry_run=False)
+
+        assert result["status"] == "migrated_success"
+        assert day_field_path(5, 2, "04_role_context.json").exists()
+
+    def test_migrate_day_renames_fields(self, temp_curriculum):
+        """Should rename fields 04→05, 05→06, 06→07."""
+        create_legacy_day(5, 3)
+        migrate_day(5, 3, dry_run=False)
+
+        # New field names should exist
+        assert day_field_path(5, 3, "05_guidelines_for_sparky.md").exists()
+        assert day_field_path(5, 3, "06_document_for_sparky.json").exists()
+        assert day_field_path(5, 3, "07_sparkys_greeting.txt").exists()
+
+        # Old field names should NOT exist
+        assert not day_field_path(5, 3, "04_guidelines_for_sparky.md").exists()
+
+    def test_migrate_day_dry_run(self, temp_curriculum):
+        """Dry-run should not modify files."""
+        create_legacy_day(6, 1)
+        result = migrate_day(6, 1, dry_run=True)
+
+        assert result["status"] == "dry_run_success"
+        assert not day_field_path(6, 1, "04_role_context.json").exists()
+
+    def test_migrate_already_7field_day(self, temp_curriculum):
+        """Should skip days already migrated."""
+        create_7field_day(7, 1)
+        result = migrate_day(7, 1, dry_run=False)
+        assert result["status"] == "already_7field"
+
+
+class TestValidation:
+    """Test validation of 7-field days."""
+
+    def test_validate_7field_day_success(self, temp_curriculum):
+        """Should validate a complete 7-field day."""
+        create_7field_day(10, 1)
+        result = validate_day_fields(10, 1)
+        assert result.is_valid()
+
+    def test_validate_6field_day_warning(self, temp_curriculum):
+        """Should warn about legacy 6-field layout."""
+        create_legacy_day(10, 2)
+        result = validate_day_fields(10, 2)
+        assert len(result.warnings) > 0
+        assert any("legacy 6-field" in str(w).lower() for w in result.warnings)
+
+    def test_validate_role_context_structure(self, temp_curriculum):
+        """Should validate role_context JSON structure."""
+        create_7field_day(11, 1)
+        # Write invalid role_context (missing required keys)
+        rc_path = day_field_path(11, 1, "04_role_context.json")
+        write_json(rc_path, {"incomplete": "data"})
+
+        result = validate_day_fields(11, 1)
+        assert len(result.warnings) > 0  # Should warn about missing keys

diff --git a/README.md b/README.md
index a1b2c3d..e4f5g6h 100644
--- a/README.md
+++ b/README.md
@@ -118,12 +118,15 @@ How Files Are Stored

 Each week gets a folder like this:
 curriculum/LatinA/Week01/
 ├── Week_Spec/              # 12 separate JSON files
 │   ├── 01_metadata.json    # Week info
 │   ├── 02_objectives.json  # Learning goals
 │   ├── 03_vocabulary.json  # Word list
 │   ├── 04_grammar_focus.md # Grammar concepts
 │   └── 99_compiled_week_spec.json  # Everything combined
 ├── Role_Context/           # Sparky personality (7 files)
 ├── activities/
-│   ├── Day1/              # 6 field files
+│   ├── Day1/              # 7 field files (updated in Patch TEQUILA Phase 2)
+│   │   ├── 01_class_name.txt
+│   │   ├── 02_summary.md
+│   │   ├── 03_grade_level.txt
+│   │   ├── 04_role_context.json          # NEW: Day-specific Sparky behavior
+│   │   ├── 05_guidelines_for_sparky.md   # (reindexed from 04)
+│   │   ├── 06_document_for_sparky.json   # (reindexed from 05)
+│   │   └── 07_sparkys_greeting.txt       # (reindexed from 06)
 │   ├── Day2/
 │   ├── Day3/
 │   └── Day4/
 └── assets/                # Supplementary materials
     ├── ChantChart.txt
     ├── Glossary.txt
     └── QuizPacket.txt

 Why split into small files?
 - Git-friendly (fewer merge conflicts)
 - Edit one part without regenerating everything
 - Track changes at granular level
+
+---
+Migrating Existing Days to 7-Field Architecture
+
+If you have existing 6-field days, use the migration script:
+
+# Migrate a single week
+python -m src.cli.migrate_to_7field --week 1
+
+# Migrate all weeks
+python -m src.cli.migrate_to_7field --all
+
+# Preview changes without modifying files
+python -m src.cli.migrate_to_7field --dry-run --all
+
+The migration script:
+1. Detects legacy 6-field days
+2. Creates default role_context (04_role_context.json) from week-level Role_Context
+3. Renames fields: 04→05, 05→06, 06→07
+4. Validates migrated structure
+5. Adds migration provenance metadata

 ---
 What You Can Do With This
